{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce993a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 0: INSTALAÇÃO DAS DEPENDÊNCIAS\n",
    "# ==============================================================================\n",
    "# Este bloco instala todas as bibliotecas necessárias da Hugging Face e outras\n",
    "# ferramentas que usaremos para processamento de imagem e avaliação.\n",
    "!pip install -q transformers datasets Pillow seqeval accelerate\n",
    "!pip install -q \"evaluate\" # Usado pela Hugging Face para métricas\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 1: CARREGAMENTO E PREPARAÇÃO DO DATASET DE EXEMPLO (FUNSD)\n",
    "# ==============================================================================\n",
    "# NOTA IMPORTANTE: Aqui usamos o dataset 'funsd' como exemplo.\n",
    "# Para seu projeto real, você substituirá esta seção para carregar\n",
    "# suas próprias imagens e anotações de Notas Fiscais.\n",
    "print(\">>> Carregando o dataset de exemplo (FUNSD)...\")\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Carregamos o dataset do Hugging Face Hub\n",
    "dataset = load_dataset(\"nielsr/funsd\")\n",
    "\n",
    "# O dataset já vem dividido em treino e teste\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "# Vamos inspecionar os rótulos (labels) do dataset\n",
    "labels = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "print(f\"\\nOs rótulos (entidades) neste dataset são: {labels}\")\n",
    "\n",
    "# Criamos mapeamentos de ID para rótulo e vice-versa.\n",
    "# Você fará o mesmo para suas entidades (ex: 'cnpj_emitente', 'valor_total').\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "print(f\"\\nMapeamento id2label: {id2label}\")\n",
    "print(f\"Mapeamento label2id: {label2id}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2: PRÉ-PROCESSAMENTO DOS DADOS\n",
    "# ==============================================================================\n",
    "# Esta é a etapa mais técnica, onde transformamos as imagens e textos em um\n",
    "# formato que o modelo LayoutLMv3 entende.\n",
    "print(\"\\n>>> Iniciando o pré-processamento dos dados...\")\n",
    "from transformers import AutoProcessor\n",
    "from PIL import Image\n",
    "\n",
    "# Carregamos o processador do modelo. Ele lida com a tokenização do texto\n",
    "# e o processamento da imagem (OCR implícito e normalização).\n",
    "model_checkpoint = \"microsoft/layoutlmv3-base\"\n",
    "processor = AutoProcessor.from_pretrained(model_checkpoint, apply_ocr=True)\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    # Pega as imagens, palavras e caixas delimitadoras\n",
    "    images = [Image.open(path).convert(\"RGB\") for path in examples['image_path']]\n",
    "    words = examples['words']\n",
    "    boxes = examples['bboxes']\n",
    "    word_labels = examples['ner_tags']\n",
    "\n",
    "    # Usa o processador para tokenizar as palavras e preparar as imagens\n",
    "    encoded_inputs = processor(images, words, boxes=boxes, word_labels=word_labels,\n",
    "                               padding=\"max_length\", truncation=True)\n",
    "\n",
    "    return encoded_inputs\n",
    "\n",
    "# Aplicamos a função de pré-processamento a todo o dataset\n",
    "processed_train_dataset = train_dataset.map(preprocess_data, batched=True, remove_columns=train_dataset.column_names, features=train_dataset.features)\n",
    "processed_eval_dataset = eval_dataset.map(preprocess_data, batched=True, remove_columns=eval_dataset.column_names, features=eval_dataset.features)\n",
    "\n",
    "# Define o formato para PyTorch\n",
    "processed_train_dataset.set_format(type=\"torch\")\n",
    "processed_eval_dataset.set_format(type=\"torch\")\n",
    "\n",
    "print(\"\\nPré-processamento concluído!\")\n",
    "print(f\"Exemplo de uma amostra processada (chaves): {processed_train_dataset[0].keys()}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 3: FINE-TUNING DO MODELO\n",
    "# ==============================================================================\n",
    "print(\"\\n>>> Configurando e iniciando o Fine-Tuning...\")\n",
    "from transformers import LayoutLMv3ForTokenClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Carregamos o modelo pré-treinado\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Carregamos a métrica 'seqeval'\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Removemos os tokens especiais\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"meu-modelo-layoutlmv3-notas-fiscais\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=3e-5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    eval_dataset=processed_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Inicia o treinamento\n",
    "print(\"\\nIniciando o treinamento. Isso levará alguns minutos...\")\n",
    "trainer.train()\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 4: SALVANDO O MODELO FINAL\n",
    "# ==============================================================================\n",
    "print(\"\\n>>> Salvando o modelo treinado localmente...\")\n",
    "trainer.save_model(\"modelo-notas-fiscais-final\")\n",
    "processor.save_pretrained(\"modelo-notas-fiscais-final\")\n",
    "print(\"Modelo salvo na pasta 'modelo-notas-fiscais-final'!\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 5: INFERÊNCIA - USANDO O MODELO PARA EXTRAIR INFORMAÇÕES\n",
    "# ==============================================================================\n",
    "print(\"\\n>>> Executando inferência em uma nova imagem...\")\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"document-question-answering\", model=\"./modelo-notas-fiscais-final\")\n",
    "\n",
    "image_to_test = Image.open(eval_dataset[0]['image_path']).convert(\"RGB\")\n",
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "model_final = AutoModelForTokenClassification.from_pretrained(\"./modelo-notas-fiscais-final\")\n",
    "processor_final = AutoProcessor.from_pretrained(\"./modelo-notas-fiscais-final\")\n",
    "\n",
    "def extract_entities(image, model, processor):\n",
    "    encoding = processor(image, return_tensors=\"pt\")\n",
    "    for k,v in encoding.items():\n",
    "      encoding[k] = v.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(**encoding)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.argmax(-1).squeeze().tolist()\n",
    "    boxes = encoding[\"bbox\"].squeeze().tolist()\n",
    "\n",
    "    results = []\n",
    "    for pred, box in zip(predictions, boxes):\n",
    "        if pred != label2id['O']:\n",
    "            results.append({\n",
    "                \"label\": model.config.id2label[pred],\n",
    "                \"box\": box\n",
    "            })\n",
    "    return results\n",
    "\n",
    "extracted_data = extract_entities(image_to_test, model_final, processor_final)\n",
    "\n",
    "print(\"\\n--- DADOS EXTRAÍDOS ---\")\n",
    "print(extracted_data)\n",
    "\n",
    "from PIL import ImageDraw\n",
    "\n",
    "draw = ImageDraw.Draw(image_to_test)\n",
    "for data in extracted_data:\n",
    "    box = [int(coord) for coord in data['box']]\n",
    "    draw.rectangle(box, outline=\"red\", width=2)\n",
    "\n",
    "print(\"\\nExibindo imagem com as entidades detectadas (salva como 'resultado.png')...\")\n",
    "image_to_test.save(\"resultado.png\")\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "img_display = cv2.imread(\"resultado.png\")\n",
    "cv2_imshow(img_display)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
